{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import gym\n",
    "\n",
    "import imitation_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps     = 50\n",
    "batch_size    = 16\n",
    "n_iterations  = 1000\n",
    "mem_size      = 10\n",
    "\n",
    "input_size    = 1\n",
    "action_size   = 4\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_policy_loss(p, a, r):\n",
    "    \"\"\"\n",
    "    p - array (n_episodes x n_steps x state_size)\n",
    "    a - array (n_episodes x n_steps x num_actions) - binary array\n",
    "    r - array (n_episodes x n_steps)\n",
    "    \"\"\"\n",
    "    n_episodes = a.shape[0]\n",
    "    n_steps    = a.shape[1]\n",
    "    n_actions  = a.shape[2]\n",
    "    \n",
    "    log_pr     = tf.zeros(shape=[n_steps, n_actions])\n",
    "    \n",
    "    for i in range(n_episodes):\n",
    "        r_cum = tf.cumsum(r[i], reverse=True)\n",
    "        r_cum = tf.expand_dims(r_cum, axis=1)\n",
    "        \n",
    "        log_pr += -tf.math.log(p)*a[i]*r_cum\n",
    "        \n",
    "    return tf.reduce_sum(log_pr)/n_episodes\n",
    "\n",
    "def gradient(model, s, a, r):\n",
    "    with tf.GradientTape() as t:\n",
    "        loss = discrete_policy_loss(model(s),a,r)\n",
    "    return t.gradient(loss, model.trainable_variables)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=[input_size]),\n",
    "    keras.layers.Dense(5, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(action_size, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v0').env.__class__(\n",
    "    map_name='4x4', is_slippery=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = imitation_learning.agent.DiscreteActionAgent(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim   = imitation_learning.simulator.Simulator(env, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay = imitation_learning.replay.EpisodeReplay(\n",
    "    input_size, action_size, num_steps, \n",
    "    size=1000, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer   = tf.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "global_step = tf.Variable(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "100 r=0.0 loss=0.00\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "200 r=0.0 loss=0.00\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "300 r=0.0 loss=0.00\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "400 r=0.0 loss=0.00\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "SF\u001b[41mF\u001b[0mF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "SFF\u001b[41mF\u001b[0m\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFF\u001b[41mF\u001b[0m\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SF\u001b[41mF\u001b[0mF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "500 r=0.0 loss=0.00\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "600 r=0.0 loss=0.00\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "700 r=0.0 loss=0.00\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "800 r=0.0 loss=0.00\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "900 r=0.0 loss=0.00\n"
     ]
    }
   ],
   "source": [
    "#TODO: implement reward-based importance sampling\n",
    "#TODO: what happens if e.g. r = 100 -10 -10 -10 40 (ok as long as cum sum ok?)\n",
    "count = 0\n",
    "avg_r = 0\n",
    "rewards = []\n",
    "for it in range(n_iterations):\n",
    "    \n",
    "    r = sim.run(render=False, num_steps=num_steps)\n",
    "    \n",
    "    avg_r = 0.9*avg_r + 0.1*r\n",
    "    rewards.append(avg_r)\n",
    "    T = sim.tuples\n",
    "    \n",
    "    replay.append(T)\n",
    "    \n",
    "    if it > batch_size:\n",
    "        S,A,R = replay.sample()\n",
    "        \n",
    "        g = gradient(model, S, A, R)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(g,model.trainable_variables), \n",
    "                                  global_step)\n",
    "        \n",
    "        loss = discrete_policy_loss(model(S),A,R)\n",
    "        \n",
    "        if it%100 == 0:\n",
    "            print(\"{} r={} loss={:.2f}\".format(it,r,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(rewards)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.run(render=True, num_steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
